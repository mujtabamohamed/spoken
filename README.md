<p align="center">
  <img src="codebase/extension/spoken-logo.png" alt="Spoken Logo" width="120" height="120">
</p>

<h1 align="center">Spoken</h1>

<p align="center">
  <strong>AI-powered YouTube transcription at your fingertips.</strong><br>
  Fast, accurate, timestamped â€” directly in your browser.
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Chrome-Extension-4285F4?style=for-the-badge&logo=google-chrome&logoColor=white" alt="Chrome Extension">
  <img src="https://img.shields.io/badge/Manifest-V3-34A853?style=for-the-badge&logo=google-chrome&logoColor=white" alt="Manifest V3">
  <img src="https://img.shields.io/badge/Whisper-AI-FF6B6B?style=for-the-badge&logo=openai&logoColor=white" alt="Whisper AI">
  <img src="https://img.shields.io/badge/License-MIT-green.svg?style=for-the-badge" alt="MIT License">
</p>

---

## ğŸ¯ Overview

**Spoken** is a privacy-focused Chrome extension that transcribes YouTube videos using state-of-the-art AI. It supports **free local transcription** using OpenAI's open-source Whisper model, or cloud-based transcription via **OpenAI Whisper API** and **Deepgram API**.

### Why Spoken?

- ğŸ”’ **Privacy First** â€” Local mode processes everything on your machine
- ğŸ’° **Free Option** â€” No API costs with local Whisper transcription
- âš¡ **Real-time Progress** â€” Live status updates during transcription
- ğŸŒ **Multi-language** â€” Supports 25+ languages with auto-detection
- ğŸ“± **Modern UI** â€” Clean sidepanel interface with dark/light mode

---

## âœ¨ Features

| Feature | Description |
|---------|-------------|
| ğŸ¬ **Auto YouTube Detection** | Automatically detects videos from various URL formats (watch, shorts, embed) |
| ğŸ¤ **Local Whisper** | FREE transcription using local Whisper model â€” no API key needed |
| ğŸŒ **Cloud APIs** | Optional OpenAI Whisper ($0.006/min) or Deepgram (~$0.0043/min) |
| ğŸ“ **Timestamps** | Optional timestamps for each segment |
| ğŸ” **Search & Highlight** | Full-text search within transcriptions with highlighting |
| ğŸ“‹ **One-Click Copy** | Copy transcription to clipboard instantly |
| ğŸ’¾ **Export Formats** | Download as TXT, SRT, or VTT subtitles |
| ğŸŒ— **Dark/Light Mode** | Automatically matches your system preference |
| âŒ¨ï¸ **Keyboard Shortcuts** | T=Transcribe, C=Copy, F=Search, Esc=Close |
| ğŸ—ƒï¸ **Smart Caching** | Cached transcriptions avoid re-processing |
| ğŸ“¤ **Audio Upload** | Transcribe local audio files directly |

---

## ğŸš€ Quick Start

### Prerequisites

Before running Spoken, install the required system dependencies:

```bash
# macOS (using Homebrew)
brew install yt-dlp ffmpeg

# For LOCAL transcription mode (free!)
brew install pipx && pipx ensurepath
pipx install openai-whisper
```

<details>
<summary><strong>Linux Installation</strong></summary>

```bash
# Ubuntu/Debian
sudo apt update
sudo apt install ffmpeg
pip install yt-dlp

# For LOCAL transcription mode
pip install openai-whisper
```

</details>

<details>
<summary><strong>Windows Installation</strong></summary>

```powershell
# Using winget
winget install yt-dlp
winget install ffmpeg

# For LOCAL transcription mode
pip install openai-whisper
```

</details>

### 1. Clone the Repository

```bash
git clone https://github.com/mujtabamohamed/spoken.git
cd spoken
```

### 2. Start the Backend Server

```bash
cd codebase/server
npm install   # First time only
npm start
```

You should see:

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  Spoken Backend Server
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  Status:     Running
  Port:       3456
  Mode:       LOCAL
  Model:      base
  Cost:       FREE! ğŸ‰
```

### 3. Load the Chrome Extension

1. Open Chrome and navigate to `chrome://extensions/`
2. Enable **Developer mode** (toggle in top-right)
3. Click **Load unpacked**
4. Select the `codebase/extension` folder

### 4. Start Transcribing!

1. Navigate to any YouTube video
2. Click the Spoken extension icon â†’ Opens sidepanel
3. Click **Transcribe**
4. Wait for the magic! âœ¨

---

## âš™ï¸ Configuration

### Transcription Modes

Spoken supports three transcription modes:

#### ğŸ–¥ï¸ Local Mode (Default â€” FREE!)

Runs Whisper directly on your machine. No API key needed, no costs.

```bash
# Start with default 'base' model
npm start

# Use a different model for better accuracy
WHISPER_MODEL=small npm start
WHISPER_MODEL=medium npm start
WHISPER_MODEL=large npm start
```

| Model | Speed | Accuracy | VRAM | Download Size |
|-------|-------|----------|------|---------------|
| `tiny` | Fastest | Basic | ~1GB | ~75MB |
| `base` | Fast | Good | ~1GB | ~140MB |
| `small` | Medium | Better | ~2GB | ~460MB |
| `medium` | Slow | Great | ~5GB | ~1.5GB |
| `large` | Slowest | Best | ~10GB | ~3GB |

#### â˜ï¸ OpenAI API Mode

Use OpenAI's cloud API for transcription (~$0.006/minute):

```bash
WHISPER_MODE=api npm start
```

Then add your API key in the extension settings.

#### â˜ï¸ Deepgram API Mode ($200 worth free credits)

Use Deepgram's API for faster, cost-effective transcription (~$0.0043/minute):

1. Start the server in API mode: `WHISPER_MODE=api npm start`
2. In the extension settings, select **Deepgram** as the provider
3. Add your Deepgram API key

### Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `PORT` | `3456` | Server port |
| `WHISPER_MODE` | `local` | `local` or `api` |
| `WHISPER_MODEL` | `base` | Local Whisper model size |

---

## ğŸ—‚ï¸ Project Structure

```
spoken/
â”œâ”€â”€ README.md                 # This file
â”œâ”€â”€ logo/                     # Brand assets
â””â”€â”€ codebase/
    â”œâ”€â”€ extension/            # Chrome extension
    â”‚   â”œâ”€â”€ manifest.json     # Extension configuration
    â”‚   â”œâ”€â”€ background.js     # Service worker
    â”‚   â”œâ”€â”€ content.js        # YouTube page detection
    â”‚   â”œâ”€â”€ sidepanel.html    # Side panel UI
    â”‚   â”œâ”€â”€ sidepanel.js      # UI logic
    â”‚   â”œâ”€â”€ sidepanel.css     # Styles
    â”‚   â”œâ”€â”€ api.js            # Whisper API client
    â”‚   â”œâ”€â”€ utils.js          # Utility functions
    â”‚   â””â”€â”€ icons/            # Extension icons
    â””â”€â”€ server/               # Backend server
        â”œâ”€â”€ package.json      # Dependencies
        â””â”€â”€ server.js         # yt-dlp + Whisper integration
```

---

## ğŸ”Œ API Reference

### Server Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/health` | `GET` | Health check & mode info |
| `/check-deps` | `GET` | Verify yt-dlp & Whisper installation |
| `/video-info` | `POST` | Get YouTube video metadata |
| `/transcribe` | `POST` | Extract audio & transcribe (SSE) |
| `/estimate-cost` | `POST` | Cost estimate for API mode |

### Example: Transcribe Request

```bash
curl -X POST http://localhost:3456/transcribe \
  -H "Content-Type: application/json" \
  -H "X-Mode: local" \
  -d '{"url": "https://www.youtube.com/watch?v=VIDEO_ID"}'
```

---

## âŒ¨ï¸ Keyboard Shortcuts

| Key | Action |
|-----|--------|
| `T` | Start transcription |
| `C` | Copy transcription to clipboard |
| `F` | Focus search input |
| `Esc` | Close settings panel |

---

## ğŸŒ Supported Languages

Spoken supports 25+ languages for transcription:

- **European**: English, Spanish, French, German, Italian, Portuguese, Dutch, Polish, Russian, Ukrainian, Czech, Swedish, Danish, Finnish, Norwegian, Greek, Romanian, Hungarian
- **Asian**: Arabic, Chinese, Hebrew, Hindi, Indonesian, Japanese, Korean, Persian, Thai, Vietnamese, Turkish, Urdu

---

## ğŸ› ï¸ Troubleshooting

<details>
<summary><strong>âŒ "whisper not found"</strong></summary>

```bash
# Ensure path is set correctly
export PATH="$HOME/.local/bin:$PATH"

# Reinstall whisper
pipx install openai-whisper

# Or use pip
pip install --user openai-whisper
```

</details>

<details>
<summary><strong>âŒ "yt-dlp not found"</strong></summary>

```bash
# macOS
brew install yt-dlp

# Linux
pip install yt-dlp

# Windows
winget install yt-dlp
```

</details>

<details>
<summary><strong>â³ First transcription is slow</strong></summary>

The first run downloads the Whisper model to `~/.cache/whisper/`. This is a one-time download. Subsequent transcriptions are much faster.

</details>

<details>
<summary><strong>ğŸ”´ Extension not detecting video</strong></summary>

1. Refresh the YouTube page
2. Make sure you're on a video page (not homepage/search)
3. Check if the server is running (`http://localhost:3456/health`)

</details>

<details>
<summary><strong>âŒ API key errors</strong></summary>

- **OpenAI**: Get your key at [platform.openai.com/api-keys](https://platform.openai.com/api-keys)
- **Deepgram**: Get your key at [console.deepgram.com](https://console.deepgram.com)
- Ensure your key has sufficient credits

</details>

---

## ğŸ¤ Contributing

We love contributions! Here's how to get started:

### Development Setup

1. **Fork & Clone**
   ```bash
   git clone https://github.com/mujtabamohamed/spoken.git
   cd spoken
   ```

2. **Install Dependencies**
   ```bash
   cd codebase/server
   npm install
   ```

3. **Start Development Server**
   ```bash
   npm run dev   # Enables auto-reload on file changes
   ```

4. **Load Extension in Chrome**
   - Go to `chrome://extensions/`
   - Enable Developer mode
   - Click "Load unpacked" â†’ Select `/extension`

### Making Changes

1. **Create a Branch**
   ```bash
   git checkout -b feature/your-awesome-feature
   ```

2. **Make Your Changes**
   - Extension code: `/extension`
   - Server code: `/server`

3. **Test Thoroughly**
   - Test with local mode
   - Test with API mode (if applicable)
   - Test on different video types (shorts, regular, live)

4. **Submit a Pull Request**
   - Write a clear description of your changes
   - Reference any related issues

### Contribution Guidelines

- ğŸ“ Follow existing code style
- ğŸ’¬ Write clear commit messages
- ğŸ§ª Test your changes thoroughly
- ğŸ“– Update documentation if needed
- ğŸ¯ Keep PRs focused and atomic

### Areas We'd Love Help With

- ğŸ¨ **UI/UX** â€” Design improvements
- ğŸ› **Bug Fixes** â€” Check out open issues
- âœ¨ **Features** â€” New export formats, integrations
- ğŸ“š **Documentation** â€” Improve guides and examples

---

## ğŸ”’ Privacy & Security

Spoken is designed with privacy in mind:

| Mode | Where Processing Happens | Data Sent Externally |
|------|-------------------------|---------------------|
| **Local** | 100% on your machine | None |
| **OpenAI API** | OpenAI servers | Audio only |
| **Deepgram API** | Deepgram servers | Audio only |

- âœ… **No Analytics** â€” We don't collect any usage data
- âœ… **No Tracking** â€” No cookies, no fingerprinting
- âœ… **Open Source** â€” Full code available for audit
- âœ… **No Account Needed** â€” Works without sign-up

---

## ğŸ“„ License

This project is licensed under the **MIT License** â€” see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Credits & Acknowledgments

- [OpenAI Whisper](https://github.com/openai/whisper) â€” State-of-the-art speech recognition
- [yt-dlp](https://github.com/yt-dlp/yt-dlp) â€” YouTube audio extraction
- [Deepgram](https://deepgram.com) â€” Fast, accurate speech-to-text API
- [Chrome Extension APIs](https://developer.chrome.com/docs/extensions/)

---

<p align="center">
  <a href="https://github.com/mujtabamohamed/spoken/issues">Report Bug</a>
  Â·
  <a href="https://github.com/mujtabamohamed/spoken/issues">Request Feature</a>
</p>
